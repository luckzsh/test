{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The layers of interest are:\n",
    "Convolutional Layer\n",
    "Activation Layer\n",
    "Max-Pool Layer\n",
    "Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.python.framework import ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#-------------------1D-data-------------------------|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 创建计算图\n",
    "ops.reset_default_graph\n",
    "sess = tf.Session()\n",
    "\n",
    "# 运行参数\n",
    "data_size = 25  # 数组大小\n",
    "conv_size = 5   # 卷积核大小\n",
    "maxpool_size = 5\n",
    "stride_size = 1 # 位移\n",
    "\n",
    "# 确保可重现，指定随机数\n",
    "seed = 13\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "# 生成 1维数组\n",
    "data_1d = np.random.normal(size=data_size)\n",
    "# 占位\n",
    "x_input_1d = tf.placeholder(shape=[data_size], dtype=tf.float32)\n",
    "\n",
    "# ----------1d卷积----------\n",
    "def conv_layer_1d(input_1d,my_filter,stride):\n",
    "    # tensorflow的\"conv2d()\"函数只能使用4D数组：[batch#, width, height, channels]\n",
    "    # 这里使用 batck=1, width=1, height=input length, channel=1，所以必须扩维到4D\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # 使用卷积stride=1, 如果需要增加到2，使用strides=[1,1,2,1]\n",
    "    convolution_output = tf.nn.conv2d(input_4d, filter=my_filter, strides=[1,1,stride,1], padding=\"VALID\")\n",
    "    # 降低维度\n",
    "    conv_output_1d = tf.squeeze(convolution_output)\n",
    "    return(conv_output_1d)\n",
    "\n",
    "# 创建卷积滤波器，设定滤波器pattern，filter与input做矩阵乘法\n",
    "#my_filter = tf.Variable(tf.random_normal(shape=[1,conv_size,1,1]))\n",
    "my_filter = tf.constant([1.,1.,2.,1.,1.], shape=[1,conv_size,1,1])\n",
    "# 创建1D卷积层\n",
    "my_convolution_output = conv_layer_1d(x_input_1d, my_filter,stride=stride_size)\n",
    "\n",
    "#--------激活函数--------\n",
    "def activation(input_1d):\n",
    "    return(tf.nn.relu(input_1d))\n",
    "\n",
    "# 创建激活层\n",
    "my_activation_output = activation(my_convolution_output)\n",
    "\n",
    "#--------池化--------\n",
    "def max_pool(input_1d, width, stride):\n",
    "    # 和'conv2d()' 类似, max_pool()需要输入4D arrays.\n",
    "    # [batch_size=1, width=1, height=num_input, channels=1]\n",
    "    input_2d = tf.expand_dims(input_1d, 0)\n",
    "    input_3d = tf.expand_dims(input_2d, 0)\n",
    "    input_4d = tf.expand_dims(input_3d, 3)\n",
    "    # Perform the max pooling with strides = [1,1,1,1]\n",
    "    # If we wanted to increase the stride on our data dimension, say by\n",
    "    # a factor of '2', we put strides = [1, 1, 2, 1]\n",
    "    # We will also need to specify the width of the max-window ('width')\n",
    "    pool_output = tf.nn.max_pool(input_4d, ksize=[1, 1, width, 1],\n",
    "                                 strides=[1, 1, stride, 1],\n",
    "                                 padding='VALID')\n",
    "    # 降维\n",
    "    pool_output_1d = tf.squeeze(pool_output)\n",
    "    return(pool_output_1d)\n",
    "\n",
    "my_maxpool_output = max_pool(my_activation_output, width=maxpool_size,stride=stride_size)\n",
    "\n",
    "#--------Fully Connected--------\n",
    "def fully_connected(input_layer, num_outputs):\n",
    "    # First we find the needed shape of the multiplication weight matrix:\n",
    "    # The dimension will be (length of input) by (num_outputs)\n",
    "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer),[num_outputs]]))\n",
    "    # Initialize such weight\n",
    "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
    "    # Initialize the bias\n",
    "    bias = tf.random_normal(shape=[num_outputs])\n",
    "    # Make the 1D input array into a 2D array for matrix multiplication\n",
    "    input_layer_2d = tf.expand_dims(input_layer, 0)\n",
    "    # Perform the matrix multiplication and add the bias\n",
    "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
    "    # Get rid of extra dimensions\n",
    "    full_output_1d = tf.squeeze(full_output)\n",
    "    return(full_output_1d)\n",
    "\n",
    "my_full_output = fully_connected(my_maxpool_output, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> 1D Data <<<<\n",
      "Input = array of length 25\n",
      "[-0.71239066  0.75376636 -0.04450308  0.45181233  1.3451017   0.5323379\n",
      "  1.3501879   0.86121136  1.4786857  -1.0453771  -0.788989   -1.261606\n",
      "  0.5628468  -0.24332625  0.9137407   0.31735092  0.12730329  2.150383\n",
      "  0.6062887  -0.02677165 -0.9841608   1.1907053   0.9528306  -1.0871816\n",
      " -0.14521134]\n",
      "my_filter shape = [1, 3, 1, 1]\n",
      "[[[[1.]]\n",
      "\n",
      "  [[1.]]\n",
      "\n",
      "  [[2.]]]]\n",
      "Convolution w/ filter, length = 3, stride size = 1, results in an array of length 23:\n",
      "[-0.04763046  1.6128879   3.0975127   2.86159     4.5778155   3.6049485\n",
      "  5.168771    0.24914289 -1.1446694  -4.3575783  -0.9249015  -1.1854117\n",
      "  2.147002    1.3051163   1.4856982   4.7454205   3.4902637   2.7031283\n",
      " -1.3888046   1.3704782   2.1122057  -0.03082728 -0.42477363]\n",
      "\n",
      "Input = above array of length 23\n",
      "ReLU element wise returns an array of length 23:\n",
      "[0.         1.6128879  3.0975127  2.86159    4.5778155  3.6049485\n",
      " 5.168771   0.24914289 0.         0.         0.         0.\n",
      " 2.147002   1.3051163  1.4856982  4.7454205  3.4902637  2.7031283\n",
      " 0.         1.3704782  2.1122057  0.         0.        ]\n",
      "\n",
      "Input = above array of length 23\n",
      "MaxPool, window length = 5, stride size = 1, results in the array of length 19\n",
      "[4.5778155  4.5778155  5.168771   5.168771   5.168771   5.168771\n",
      " 5.168771   0.24914289 2.147002   2.147002   2.147002   4.7454205\n",
      " 4.7454205  4.7454205  4.7454205  4.7454205  3.4902637  2.7031283\n",
      " 2.1122057 ]\n",
      "\n",
      "Input = above array of length 19\n",
      "Fully connected layer on all 4 rows with 5 outputs:\n",
      "[ 0.22666657  0.14913116  1.8357348   1.5420072  -4.167526  ]\n"
     ]
    }
   ],
   "source": [
    "# Run graph\n",
    "# Initialize Variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "feed_dict = {x_input_1d: data_1d}\n",
    "\n",
    "print('>>>> 1D Data <<<<')\n",
    "\n",
    "# Convolution Output\n",
    "print('Input = array of length %d' % (x_input_1d.shape.as_list()[0]))\n",
    "print(sess.run(x_input_1d, feed_dict=feed_dict))\n",
    "print('my_filter shape = %s, value as below:' %(my_filter.shape.as_list()))\n",
    "print(sess.run(my_filter))\n",
    "print('Convolution w/ filter, length = %d, stride size = %d, results in an array of length %d:' % \n",
    "      (conv_size,stride_size,my_convolution_output.shape.as_list()[0]))\n",
    "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
    "\n",
    "# Activation Output\n",
    "print('\\nInput = above array of length %d' % (my_convolution_output.shape.as_list()[0]))\n",
    "print('ReLU element wise returns an array of length %d:' % (my_activation_output.shape.as_list()[0]))\n",
    "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
    "\n",
    "# Max Pool Output\n",
    "print('\\nInput = above array of length %d' % (my_activation_output.shape.as_list()[0]))\n",
    "print('MaxPool, window length = %d, stride size = %d, results in the array of length %d' %\n",
    "     (maxpool_size,stride_size,my_maxpool_output.shape.as_list()[0]))\n",
    "print(sess.run(my_maxpool_output, feed_dict=feed_dict))\n",
    "\n",
    "# Fully Connected Output\n",
    "print('\\nInput = above array of length %d' % (my_maxpool_output.shape.as_list()[0]))\n",
    "print('Fully connected layer on all 4 rows with %d outputs:' % \n",
    "      (my_full_output.shape.as_list()[0]))\n",
    "print(sess.run(my_full_output, feed_dict=feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(3), Dimension(1), Dimension(1)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_filter.shape.as_list()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
